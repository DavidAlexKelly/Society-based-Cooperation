{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69e2fe07",
      "metadata": {
        "id": "69e2fe07"
      },
      "outputs": [],
      "source": [
        "!pip install deap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "v4eZFTNHnkTl",
      "metadata": {
        "id": "v4eZFTNHnkTl"
      },
      "outputs": [],
      "source": [
        "import random, time, turtle, math\n",
        "import numpy as np\n",
        "from deap import base, creator, tools\n",
        "from IPython import display as dis\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2167ca2c",
      "metadata": {
        "id": "2167ca2c"
      },
      "outputs": [],
      "source": [
        "class agent():\n",
        "    \n",
        "    def __init__(self,group,wealth):\n",
        "        self.group = group\n",
        "        self.wealth = wealth\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ae63977",
      "metadata": {
        "id": "9ae63977"
      },
      "source": [
        "Above I have defined a simple agent. This agent only needs to be a simple object that holds the values of its group and its wealth in order for my program to work. N number of these agents will be created which are then split evenly into the four societies and have a starting wealth of zero. These agents are all given their own individual neural networks which form the basis of my program and determine the genotypes and phenotypes. \n",
        "\n",
        "The genotypes are represented by the number of neurons in each agent's neural network. Each neural network has the same shape and thus each agentâ€™s genotype is the same. The shape of the neural network is that of 3 input neurons, 6 hidden neurons and 4 output neurons. The three input neurons are needed to take in information about games played. They take in whether or not the agent \"won\" in a game, whether or not the agent was in the same group as its opponent and whether or not the opponent had more wealth than the agent. There needed to be 4 output neurons to represent the four societies the agent could choose to switch to.\n",
        "The number of hidden layer neurons was chosen through research online. From the research i determined that the number of hidden neurons should equal 2/3 of the input nodes plus the output nodes which is of course 6. Through testing having 6 neurons seemed to be ideal to get the results I wanted and to avoid overfitting. So, through all of this I ended up with a 13 number genotype.\n",
        "\n",
        "The phenotypes are the weights of the individual neurons in each agent's neural network. The weights of the neurons ultimately decide if a given agent should swap groups or not. These weights are initially given weights randomly between -1 and 1. Mutation was used in order to evolve the agents and give variance to these weights. This was done by using a gaussian distribution which had a mean of 0 allowing values to be selected from either side of 0. Using a sigma value of 0.2 allows for mutation to be selected within the range of -1 and 1. The independent mutation probability is selected at 0.2. I also employed tournament selection to reduce stochastic noise. It is used to add variance wow still allowing the fittest individuals to pass on. I found using a tournament size of 10 was appropriate as it showed a nice balance of variance and allowing the fittest individuals to pass through. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f53e0e2",
      "metadata": {
        "id": "9f53e0e2"
      },
      "outputs": [],
      "source": [
        "class NN(object):\n",
        "    def __init__(self, numInput, numHidden1,numOutput):\n",
        "        self.fitness = 0,\n",
        "        self.numInput = numInput + 1 # Add bias node from input to hidden layer 1 only,\n",
        "        self.numHidden1 = numHidden1 # Feel free to adapt the code to add more biases if you wish,\n",
        "        self.numOutput = numOutput\n",
        "\n",
        "        self.w_i_h1 = np.random.randn(self.numHidden1, self.numInput) \n",
        "        self.w_h1_o = np.random.randn(self.numOutput, self.numHidden1)\n",
        "\n",
        "        self.ReLU = lambda x : max(0,x)\n",
        "\n",
        "    def sigmoid(self,x):\n",
        "        try:\n",
        "            ans = (1 / (1 + math.exp(-x)))\n",
        "        except OverflowError:\n",
        "            ans = float('inf')\n",
        "        return ans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7541961",
      "metadata": {
        "id": "e7541961"
      },
      "outputs": [],
      "source": [
        "class NN(NN):\n",
        "        def feedForward(self, inputs):\n",
        "            inputsBias = inputs[:]\n",
        "            inputsBias.insert(len(inputs),1)             # Add bias input\n",
        "    \n",
        "            h1 = np.dot(self.w_i_h1, inputsBias)         # feed input to hidden layer 1\n",
        "            h1 = [self.ReLU(x) for x in h1]              # Activate hidden layer1\n",
        "              \n",
        "            output = np.dot(self.w_h1_o, h1)             # feed to output layer\n",
        "            output = [self.sigmoid(x) for x in output]   # Activate output layer\n",
        "            return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44be5d5b",
      "metadata": {
        "id": "44be5d5b"
      },
      "outputs": [],
      "source": [
        "class NN(NN):\n",
        "        \n",
        "        def getWeightsLinear(self):\n",
        "            flat_w_i_h1 = list(self.w_i_h1.flatten())\n",
        "            flat_w_h2_o = list(self.w_h1_o.flatten())\n",
        "            return( flat_w_i_h1 + flat_w_h1_o )\n",
        "    \n",
        "        def setWeightsLinear(self, Wgenome):\n",
        "            numWeights_I_H1 = self.numHidden1 * self.numInput\n",
        "            numWeights_H2_O = self.numOutput * self.numHidden1\n",
        "    \n",
        "            self.w_i_h1 = np.array(Wgenome[:numWeights_I_H1])\n",
        "            self.w_i_h1 = self.w_i_h1.reshape((self.numHidden1, self.numInput))\n",
        "            \n",
        "    \n",
        "            self.w_h1o = np.array(Wgenome[(numWeights_I_H1):])\n",
        "            self.w_h1o = self.w_h1o.reshape((self.numOutput, self.numHidden1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5c55d64",
      "metadata": {
        "id": "e5c55d64"
      },
      "outputs": [],
      "source": [
        "num_agents = 400\n",
        "wealth = 0\n",
        "num_games = 3200\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "tournamentSize = 10\n",
        "muProb = 0.2\n",
        "population = 100\n",
        "generations = 200\n",
        "muSigma = 0.2\n",
        "\n",
        "\n",
        "inputLayer = 3\n",
        "HiddenNodes = 6\n",
        "outputLayer = 4\n",
        "\n",
        "IND_SIZE = ((inputLayer+1) * (HiddenNodes)) + ((HiddenNodes) * (outputLayer))\n",
        "\n",
        "myNet1 = NN(inputLayer, HiddenNodes, outputLayer)\n",
        "myNet2 = NN(inputLayer, HiddenNodes, outputLayer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e69ddeab",
      "metadata": {
        "id": "e69ddeab"
      },
      "outputs": [],
      "source": [
        "def run_game(pop,num_games,adaptive):\n",
        "    count = 0\n",
        "    popDict = {}\n",
        "    for popIndex in range(len(pop)):\n",
        "        #need to add a check that no two sums are the same\n",
        "        #if any are, add a small number to one of the values in the indiv\n",
        "        \n",
        "        summed = round(sum(pop[popIndex]),5)\n",
        "        \n",
        "        if summed in popDict:\n",
        "            summed += summed/1000\n",
        "            summed = round(summed,5)\n",
        "            \n",
        "        popDict[summed] = agent(popIndex%4,0)\n",
        "        \n",
        "        \n",
        "    hm = np.zeros(len(pop))\n",
        "    for i in range(num_games):\n",
        "\n",
        "        player1Index = random.randint(0,len(pop)-1)\n",
        "        player2Index = random.randint(0,len(pop)-1)\n",
        "        while player1Index == player2Index:\n",
        "            player2Index = random.randint(0,len(pop)-1)\n",
        "\n",
        "        players = [popDict[round(sum(pop[player1Index]),5)],popDict[round(sum(pop[player2Index]),5)]]\n",
        "        \n",
        "    \n",
        "        \n",
        "        myNet1.setWeightsLinear(pop[player1Index])\n",
        "        myNet2.setWeightsLinear(pop[player2Index])\n",
        "\n",
        "        decision = []\n",
        "\n",
        "        for j in range(len(players)):\n",
        "            if players[j].group == 0:\n",
        "                decision.append(0)\n",
        "            elif players[j].group == 1:\n",
        "                if players[(j+1)%2].group == 1:\n",
        "                        decision.append(0)\n",
        "                else:\n",
        "                    decision.append(1)\n",
        "            elif players[j].group == 2:\n",
        "                if players[(j+1)%2].group == 2:\n",
        "                    decision.append(1)\n",
        "                else:\n",
        "                    decision.append(0)\n",
        "            \n",
        "            else:\n",
        "                decision.append(1)\n",
        "                \n",
        "\n",
        "\n",
        "        \n",
        "        won = []\n",
        "        temp1 = players[0].wealth\n",
        "        temp2 = players[1].wealth\n",
        "        if (decision[0] == 0) and (decision[1] == 0):\n",
        "            players[0].wealth += 4\n",
        "            players[1].wealth += 4\n",
        "            won.append(1)\n",
        "            won.append(1)\n",
        "        elif (decision[0] == 1) and (decision[1] == 0):\n",
        "            players[0].wealth += 6\n",
        "            won.append(1)\n",
        "            won.append(0)\n",
        "        elif (decision[0] == 0) and (decision[1] == 1):\n",
        "            players[1].wealth += 6\n",
        "            won.append(0)\n",
        "            won.append(1)\n",
        "        else:\n",
        "            players[0].wealth += 1\n",
        "            players[1].wealth += 1\n",
        "            won.append(0)\n",
        "            won.append(0)\n",
        "            \n",
        "        if(players[0].wealth - temp1 == 8):\n",
        "            players[0].wealth -= 4\n",
        "            players[1].wealth -= 4\n",
        "            \n",
        "        if(players[0].wealth - temp1 == 2):\n",
        "            players[0].wealth -= 1\n",
        "            players[1].wealth -= 1\n",
        "        \n",
        "        \n",
        "\n",
        "        nets = [myNet1, myNet2]\n",
        "        for j in range(2):\n",
        "            \n",
        "            same_group = int(players[j].group == players[(j+1)%2].group)\n",
        "            wealth_comparison = int(players[j].wealth >= players[(j+1)%2].wealth)\n",
        "            winner = won[j]\n",
        "            \n",
        "            state = [same_group,winner,wealth_comparison]\n",
        "\n",
        "            output = nets[j].feedForward(state)\n",
        "            new_group = np.argmax(output, axis=0)\n",
        "            #print(output)\n",
        "            #print(new_group)\n",
        "            if adaptive == True:\n",
        "                players[j].group = new_group\n",
        "    \n",
        "    \n",
        "    grouplist = []\n",
        "    for i in range(len(pop)):\n",
        "        grouplist.append(popDict[round(sum(pop[i]),5)].group)\n",
        "    \n",
        "    \n",
        "    \n",
        "    return popDict, grouplist"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c410d59",
      "metadata": {
        "id": "9c410d59"
      },
      "source": [
        "Above you can see the code which is responsible for actually running the games and determining the fitness. Here the weights of each agentsâ€™ neurons are taken in to be changed based on the games. Firstly, two of these agents are randomly selected to play the game together. Depending on their society and how this society interacts with its opponentâ€™s society wealth is added on accordingly. Then for each agent it uses the neural network to determine which society it should join. Three inputs are used to be taken in by the neural network which are whether the agent \"won\" the game, whether or not the agent was in the same group as its opponent and whether or not the opponent had more wealth than the agent. The outputs of this neural network refer to the four societies which then the agent can join. The output neuron which results in the highest value will be the society which the agent joins. \n",
        "\n",
        "This process is repeated for a user selected number of times each time picking new random agents to play against each other. The fitness which I have used to evolve my agents is that of wealth. Agents which have a higher fitness after the selected number of games will be more likely to proceed in the mutation process. The code above returns the fitness of every agent that played in the games to be assessed and evolved.\n",
        "\n",
        "This code is also used to run the game in a non-adaptive setting. This is simply done by making it so the agents canâ€™t change their society regardless of the outcomes of the neural networks.\n",
        "\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "268a7543",
      "metadata": {
        "id": "268a7543"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a527102",
      "metadata": {
        "id": "6a527102"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b252caac",
      "metadata": {
        "id": "b252caac"
      },
      "outputs": [],
      "source": [
        "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
        "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
        "toolbox = base.Toolbox()\n",
        "toolbox.register(\"attr_float\", random.uniform, -1.0, 1.0)\n",
        "toolbox.register(\"individual\", tools.initRepeat, creator.Individual,\n",
        "                 toolbox.attr_float, n=IND_SIZE)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cce95b92",
      "metadata": {
        "id": "cce95b92"
      },
      "outputs": [],
      "source": [
        "\n",
        "def evaluate(indiv, popDict):\n",
        "    key = round(sum(indiv), 5)\n",
        "    if key in popDict:\n",
        "        return popDict[round(sum(indiv), 5)].wealth,\n",
        "    return 0,\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c24114f2",
      "metadata": {
        "id": "c24114f2"
      },
      "outputs": [],
      "source": [
        "toolbox.register(\"evaluate\", evaluate)\n",
        "toolbox.register(\"select\", tools.selTournament, tournsize=tournamentSize)\n",
        "\n",
        "toolbox.register(\"mutate\", tools.mutGaussian, mu=0.0, sigma=muSigma, indpb=muProb)\n",
        "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acf52d62",
      "metadata": {
        "id": "acf52d62"
      },
      "outputs": [],
      "source": [
        "stats = tools.Statistics(key=lambda ind: ind.fitness.values)\n",
        "stats.register(\"avg\", np.mean)\n",
        "stats.register(\"std\", np.std)\n",
        "stats.register(\"min\", np.min)\n",
        "stats.register(\"max\", np.max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f226ed3",
      "metadata": {
        "id": "8f226ed3"
      },
      "outputs": [],
      "source": [
        "logbook = tools.Logbook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a6b888a",
      "metadata": {
        "id": "1a6b888a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62a6413f",
      "metadata": {
        "id": "62a6413f"
      },
      "outputs": [],
      "source": [
        "\n",
        "def evolve(adaptive):\n",
        "    data = []\n",
        "    meanlist=[]\n",
        "    maxlist=[]\n",
        "    minlist=[]\n",
        "    grouplist=[0,0,0,0]\n",
        "    grouplist2 = [[],[],[],[]]\n",
        "    total_score =0\n",
        "    pop = toolbox.population(n=num_agents)\n",
        "    for g in range(generations):\n",
        "        print(\"-- Generation %i --\" % g)\n",
        "        #myNet.setWeightsLinear(indiv)\n",
        "\n",
        "        popDict = run_game(pop,num_games,adaptive)\n",
        "\n",
        "        offspring = toolbox.select(pop, len(pop))\n",
        "        offspring = list(map(toolbox.clone, offspring))\n",
        "\n",
        "        for mutant in offspring:\n",
        "            toolbox.mutate(mutant)\n",
        "            del mutant.fitness.values\n",
        "\n",
        "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
        "\n",
        "        popDict,groups = run_game(invalid_ind,num_games,adaptive)\n",
        "        fitnesses = [toolbox.evaluate(indiv, popDict) for indiv in invalid_ind]\n",
        "        mean = 0\n",
        "        count = 0\n",
        "        for i in fitnesses:\n",
        "            mean += i[0]\n",
        "\n",
        "        mean = mean/len(fitnesses)\n",
        "\n",
        "        print(\"average wealth: \",mean)\n",
        "\n",
        "\n",
        "        for i in groups:\n",
        "            if i == 0:\n",
        "                grouplist[0] += 1\n",
        "            elif i == 1:\n",
        "                grouplist[1] += 1\n",
        "            elif i == 2:\n",
        "                grouplist[2] += 1\n",
        "            elif i == 3:\n",
        "                grouplist[3] += 1\n",
        "\n",
        "        for i in range(len(grouplist)):\n",
        "            grouplist[i] = grouplist[i]/len(groups)\n",
        "            grouplist2[i].append(round(grouplist[i],4))\n",
        "\n",
        "        meanlist.append(mean)\n",
        "        maxlist.append(max(fitnesses))\n",
        "        minlist.append(min(fitnesses))\n",
        "\n",
        "        for ind, fit in zip(invalid_ind, fitnesses):\n",
        "             ind.fitness.values = fit\n",
        "        pop[:] = offspring\n",
        "        record = stats.compile(pop)\n",
        "        logbook.record(gen=g, **record)\n",
        "        data.append(fitnesses)\n",
        "        \n",
        "    return meanlist,maxlist,minlist,data,grouplist2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f64d93e",
      "metadata": {
        "id": "7f64d93e"
      },
      "source": [
        "Above is the code which handles the evolution of the agents. It is responsible for setting up the agents and passing them of into the games to have their fitnesses determined. It then takes the fitnesses and decides which agents to mutate and which agents should be allowed to progress in the tournament. This is done for a user selected number of generations. Even though the agents start of with 0 wealth each game and in their correct groups the neural network information is kept and used in the next run of games. This allows each progressive generation to learn faster and reach higher fitnesses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b9350ee",
      "metadata": {
        "id": "9b9350ee"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "meanlist,maxlist,minlist,data,grouplist = evolve(True)\n",
        "finish = time.time()\n",
        "\n",
        "print(\"Time taken for adaptive program: \", finish - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8600114a",
      "metadata": {
        "id": "8600114a"
      },
      "outputs": [],
      "source": [
        "plt.ion()\n",
        "\n",
        "\n",
        "x = range(0,len(meanlist))        \n",
        "y = meanlist\n",
        "plt.title(\"Wealth per generation\") \n",
        "plt.xlabel(\"Generation\") \n",
        "plt.ylabel(\"Wealth\") \n",
        "plt.plot(x,y)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.title(\"Wealth per generation\") \n",
        "plt.xlabel(\"Generation\") \n",
        "plt.ylabel(\"Wealth\") \n",
        "plt.plot(x,maxlist,label = \"Maximum\")\n",
        "plt.plot(x,minlist,label = \"Minimum\")\n",
        "plt.legend(loc='best')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "plt.title(\"Group percentage per generation\") \n",
        "plt.xlabel(\"Generation\") \n",
        "plt.ylabel(\"Percentage\") \n",
        "plt.plot(x,grouplist[0],label = \"Saints\")\n",
        "plt.plot(x,grouplist[1],label = \"Buddies\")\n",
        "plt.plot(x,grouplist[2],label = \"Fight Club\")\n",
        "plt.plot(x,grouplist[3],label = \"Vandals\")\n",
        "plt.legend(loc='best')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2a2c2a1",
      "metadata": {
        "id": "e2a2c2a1"
      },
      "source": [
        "Above can be seen the results of running the games with adaptation turned on.\n",
        "\n",
        "The average wealth against generations is plotted in the first graph. Here we can see an initial dip in the wealth as the program assesses the viability of different strategies and then a sharp uptick as it finds its strategy. This then levels of around the level of 8(number of games / number of agents) which i determine to be the theoretical maximum average wealth of this game. This shows that the program is adapting and finding the best solution to this task.\n",
        "\n",
        "Next can be seen the maximum and minimum wealth per generation. The minimum fluctuates around the same values fairly consistently for the duration. The maximum initially increases before then also fluctuating around similar values. This shows that variance is still in play as we minimum scores are still consistent but that the program is clearly adapting as maximum scores increase.\n",
        "\n",
        "The next graph reveals the strategy which the program is ultimately settling on. This graph shows the percentage of agents in each of the four societies against generations. It clearly shows that the preferred strategy employed by the adaptive program is to favour the \"buddies\" society. Over time the other societies sharply fall approaching 0 agents in these societies while all agents move to the buddies society. This makes sense as cooperating gives them the most consistent high rewards and by being in the buddies group they can also make sure they never get zero wealth rewards. This is because unless itâ€™s against its own group it will always not cooperate netting itself at least a point and sometimes six. It also makes sense that all the agents would want to be in buddies seeing as this way they can all cooperate together with low risk and maximize their individual wealth.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c5356b6",
      "metadata": {
        "id": "4c5356b6"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "meanlist2,maxlist2,minlist2,data2,grouplist2 = evolve(False)\n",
        "finish = time.time()\n",
        "print(\"Time taken for non-adaptive program: \", finish - start)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f84e706",
      "metadata": {
        "id": "8f84e706"
      },
      "outputs": [],
      "source": [
        "plt.ion()\n",
        "print(len(grouplist2))\n",
        "\n",
        "x = range(0,len(meanlist))        \n",
        "y = meanlist2\n",
        "plt.title(\"Wealth per generation\") \n",
        "plt.xlabel(\"Generation\") \n",
        "plt.ylabel(\"Wealth\") \n",
        "plt.plot(x,y)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "plt.title(\"Wealth per generation\") \n",
        "plt.xlabel(\"Generation\") \n",
        "plt.ylabel(\"Wealth\") \n",
        "plt.plot(x,maxlist2,label = \"Maximum\")\n",
        "plt.plot(x,minlist2,label = \"Minimum\")\n",
        "plt.legend(loc='best')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9ed8778",
      "metadata": {
        "id": "f9ed8778"
      },
      "source": [
        "Above can be seen the results of running the games with adaptation turned off.\n",
        "\n",
        "The first graph shows the average wealth plotted against generation. Obviously there is no trend in the graph as there is no learning going on and each generation is going to start from the same point and average around the same. As a result, the average wealth per generation can be seen to be much lower than the adaptive program.\n",
        "\n",
        "This lack of learning can also be shown in the second graph which shows the maximum and minimum wealth per generation. Here we see the same with no trend in either plot showing that the program just stagnates after the first generation and isnâ€™t learning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ca5ae8f",
      "metadata": {
        "id": "6ca5ae8f"
      },
      "source": [
        "The time taken for each program is displayed below each of their respective results, the program was run on google colab with no hardware acceleration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8f1b9ff8",
      "metadata": {
        "id": "8f1b9ff8"
      },
      "outputs": [],
      "source": [
        "from scipy import stats\n",
        "\n",
        "\n",
        "format_data = []\n",
        "format_data2 = []\n",
        "for i in data[-1]:\n",
        "    format_data.append(i[0])\n",
        "format_data = np.array(format_data)\n",
        "\n",
        "for i in data2[-1]:\n",
        "    format_data2.append(i[0])\n",
        "format_data2 = np.array(format_data2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "KSStatistic, pvalue = stats.epps_singleton_2samp(format_data2, format_data)\n",
        "print(\"Epps-Singleton test:\")\n",
        "print(\"P-value: \"+ str(pvalue))\n",
        "\n",
        "statistic ,critical_values, significance_level = stats.anderson_ksamp([format_data2, format_data])\n",
        "print(\"Anderson-Darling test :\")\n",
        "print(\"Significance level: \"+str(significance_level))\n",
        "\n",
        "KSStatistic, pvalue = stats.ks_2samp(format_data2, format_data,alternative='greater', mode='auto')\n",
        "print(\"Two-sample Kolmogorov-Smirnov test:\")\n",
        "print(\"P-value: \"+ str(pvalue))\n",
        "print(\"\\n\")\n",
        "\n",
        "\n",
        "print(\"Average adaptive wealth: \"+ str(sum(format_data)/len(format_data)))\n",
        "print(\"Standard diviation of adaptive wealth: \"+ str(np.std(format_data)))\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Average non-adaptive wealth: \"+ str(sum(format_data2)/len(format_data2)))\n",
        "print(\"Standard diviation of non-adaptive wealth: \"+ str(np.std(format_data2)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0994a168",
      "metadata": {
        "id": "0994a168"
      },
      "source": [
        "In the above code I further compared the adaptive and no adaptive programs through a series of statistical tests. In these tests I compared the game of each programs last generation. To do this it must be determined that the adapted wealth is of a different distribution to the non-adapted wealth.\n",
        "\n",
        "I did this by using the Epps-Singleton test, the Anderson-Darling test and the Twi-sample Kolmogorov-Smirnov test. Using a threshold of 0.01 it can be clearly seen that they are of different distributions as the null hypothesis rejects due to the fact that they all fall far below the threshold. This shows that there is a definite behaviour which the adapted program is exhibiting meaning it is definitely adapting to its input.\n",
        "\n",
        "However, these tests do not tell us if this behaviour is necessarily positive. To statistically determine this fact I calculated the average and standard deviation of each of the programs. A higher mean with lower standard deviation would indicate positive change which is what we ultimately see. This shows that higher wealth across the population was achieved and proves the program learned positive change\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "269703b4",
      "metadata": {
        "id": "269703b4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}